{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "- Data Analysis for: Nudging Healthy Choices: Leveraging LLM-Generated Hashtags and Explanations in Personalized Food Recommendations\n",
    "- UMAP2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload \n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./rd_data')\n",
    "from rd_data import *\n",
    "\n",
    "palette = 'Set2'\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract approved\n",
    "def approved(prolific_export_pth, personal_info_pth,profile_pth, selected_pth, evaluation_pth, condition_pth, n_condition):\n",
    "    DF = pd.read_csv(prolific_export_pth)\n",
    "    perInfo = pd.read_csv(personal_info_pth)\n",
    "    \n",
    "    profile = pd.read_csv(profile_pth)\n",
    "    profile = profile.drop(columns=['id','title'])\n",
    "    \n",
    "    selected = pd.read_csv(selected_pth)\n",
    "    selected = selected.drop(columns=['id','created','session_id'])\n",
    "    \n",
    "    evaluation = pd.read_csv(evaluation_pth)\n",
    "    evaluation = evaluation.drop(columns=['id','title','created','session_id'])\n",
    "    \n",
    "    \n",
    "    approved = DF.loc[DF.Status == 'APPROVED']\n",
    "    approved_Info = pd.merge(approved['Participant id'],perInfo, left_on='Participant id', right_on='session_id')\n",
    "    \n",
    "    approved_Info = approved_Info.drop(columns=['Participant id','title', 'created'])\n",
    "    approved_Info.rename(columns={'id':'person'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    Info_profile = pd.merge(approved_Info, profile, on='person')\n",
    "    Info_profile_selected = pd.merge(Info_profile, selected, on='person')\n",
    "    Info_profile_selected_eval = pd.merge(Info_profile_selected, evaluation, on='person')\n",
    "    \n",
    "    Info_profile_selected_eval.replace({'Strongly_Disagree':1, 'Disagree':2, 'Neutral':3, 'Agree':4, 'Strongly_Agree':5}, inplace=True)\n",
    "    Info_profile_selected_eval['condition'] = condition_pth\n",
    "    Info_profile_selected_eval['n_condition'] = n_condition\n",
    "    \n",
    "    return Info_profile_selected_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 49)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## no label approved \n",
    "prolific_export = './noLabel/No_ProlificExport.csv'\n",
    "personal_info = './noLabel/NoPersonalInfo.csv'\n",
    "profile = './noLabel/NoProfile.csv'\n",
    "selected = './noLabel/NoRecipe.csv'\n",
    "evaluation ='./noLabel/NoEvaluateChoices.csv'\n",
    "\n",
    "No_label_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'noLabel', 0)\n",
    "No_label_condition.person = No_label_condition.person + 1000\n",
    "No_label_condition[0:60].to_csv('./Condition_csv/Nolabel.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "## label condi\n",
    "prolific_export = './Labels/No_ProlificExport.csv'\n",
    "personal_info = './Labels/NoPersonalInfo.csv'\n",
    "profile = './Labels/NoProfile.csv'\n",
    "selected = './Labels/NoRecipe.csv'\n",
    "evaluation ='./Labels/NoEvaluateChoices.csv'\n",
    "\n",
    "Labels_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Label',1)\n",
    "Labels_condition.person = Labels_condition.person + 2000\n",
    "Labels_condition = Labels_condition[0:60]\n",
    "Labels_condition.to_csv('./Condition_csv/labels.csv', index=False)\n",
    "\n",
    "## hash\n",
    "prolific_export = './Hashtags/No_ProlificExport.csv'\n",
    "personal_info = './Hashtags/NoPersonalInfo.csv'\n",
    "profile = './Hashtags/NoProfile.csv'\n",
    "selected = './Hashtags/NoRecipe.csv'\n",
    "evaluation ='./Hashtags/NoEvaluateChoices.csv'\n",
    "\n",
    "Hashtags_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Hashtags',3)\n",
    "Hashtags_condition.person = Hashtags_condition.person + 3000\n",
    "Hashtags_condition = Hashtags_condition[0:60]\n",
    "Hashtags_condition.to_csv('./Condition_csv/hashtags.csv', index=False)\n",
    "\n",
    "## Explanation\n",
    "prolific_export = './Explanation/No_ProlificExport.csv'\n",
    "personal_info = './Explanation/NoPersonalInfo.csv'\n",
    "profile = './Explanation/NoProfile.csv'\n",
    "selected = './Explanation/NoRecipe.csv'\n",
    "evaluation ='./Explanation/NoEvaluateChoices.csv'\n",
    "\n",
    "Explanation_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Explanation',4)\n",
    "Explanation_condition.person = Explanation_condition.person + 5000\n",
    "Explanation_condition =  Explanation_condition[0:60]\n",
    "Explanation_condition.to_csv('./Condition_csv/explanation.csv', index=False)\n",
    "\n",
    "\n",
    "allCondition = pd.concat([No_label_condition, Labels_condition, Hashtags_condition, Explanation_condition], axis=0)\n",
    "allCondition.to_csv('./Condition_csv/allCondition.csv', index=False)\n",
    "allCondition.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA across all conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 df      sum_sq    mean_sq         F    PR(>F)\n",
      "C(condition)    3.0   58.750000  19.583333  4.690936  0.003346\n",
      "Residual      236.0  985.233333   4.174718       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Fit the OLS model for 'Labelling Condition' only (no interactions with other factors)\n",
    "model = ols('fsa_score ~ C(condition)', data=allCondition).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "                df      sum_sq    mean_sq         F    PR(>F)\n",
      "Label          1.0   16.805556  16.805556  4.025555  0.045957\n",
      "Explanation    1.0   25.069444  25.069444  6.005064  0.014992\n",
      "Hashtags       1.0   16.875000  16.875000  4.042190  0.045514\n",
      "Residual     236.0  985.233333   4.174718       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "df_condition = allCondition\n",
    "df_condition['condition'] = pd.Categorical(df_condition['condition'], categories=['Nolabel', 'Label','Explanation', 'Hashtags'], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "data_dummies = pd.get_dummies(df_condition['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "data_with_dummies = pd.concat([df_condition, data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (label1, label2, label3) as predictors\n",
    "model = ols('fsa_score ~ Label + Explanation+Hashtags', data=data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F-statistics: These show how much each condition (relative to \"nolabel\") affects the variance in the FSA_score.\n",
    "\n",
    "        - The F-statistic for explanation is 6.00, which indicates the amount of variance explained by this condition compared to nolabel.\n",
    "        - The F-statistic for hashtags is  4.042190, and labels is 4.025555, both of which show the amount of variance explained by these conditions compared to nolabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.056\n",
      "Model:                            OLS   Adj. R-squared:                  0.044\n",
      "Method:                 Least Squares   F-statistic:                     4.691\n",
      "Date:                Mon, 16 Dec 2024   Prob (F-statistic):            0.00335\n",
      "Time:                        15:37:02   Log-Likelihood:                -510.01\n",
      "No. Observations:                 240   AIC:                             1028.\n",
      "Df Residuals:                     236   BIC:                             1042.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               7.2833      0.264     27.612      0.000       6.764       7.803\n",
      "Label[T.True]          -1.2500      0.373     -3.351      0.001      -1.985      -0.515\n",
      "Explanation[T.True]    -1.1667      0.373     -3.127      0.002      -1.902      -0.432\n",
      "Hashtags[T.True]       -0.7500      0.373     -2.011      0.046      -1.485      -0.015\n",
      "==============================================================================\n",
      "Omnibus:                       28.067   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.692\n",
      "Skew:                           0.831   Prob(JB):                     2.16e-07\n",
      "Kurtosis:                       2.446   Cond. No.                         4.79\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LLM and Labels intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_DF = allCondition.loc[(allCondition['condition'] == 'noLabel') | (allCondition['condition'] == 'Label')]\n",
    "llm_DF = allCondition.loc[(allCondition['condition'] == 'Hashtags') | (allCondition['condition'] == 'Explanation')]\n",
    "\n",
    "label_DF.to_csv('./Condition_csv/labels_data.csv', index=False)\n",
    "llm_DF.to_csv('./Condition_csv/llm_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "Explanation    60\n",
       "Hashtags       60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_DF.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "             df      sum_sq    mean_sq          F    PR(>F)\n",
      "Label       1.0   46.875000  46.875000  11.194219  0.001101\n",
      "Residual  118.0  494.116667   4.187429        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "\n",
    "label_DF['condition'] = pd.Categorical(label_DF['condition'], categories=['Nolabel', 'Label'], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "label_data_dummies = pd.get_dummies(label_DF['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "label_data_with_dummies = pd.concat([label_DF, label_data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (label1, label2, label3) as predictors\n",
    "model = ols('fsa_score ~ Label', data=label_data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.079\n",
      "Method:                 Least Squares   F-statistic:                     11.19\n",
      "Date:                Mon, 16 Dec 2024   Prob (F-statistic):            0.00110\n",
      "Time:                        16:44:48   Log-Likelihood:                -255.19\n",
      "No. Observations:                 120   AIC:                             514.4\n",
      "Df Residuals:                     118   BIC:                             520.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         7.2833      0.264     27.570      0.000       6.760       7.806\n",
      "Label[T.True]    -1.2500      0.374     -3.346      0.001      -1.990      -0.510\n",
      "==============================================================================\n",
      "Omnibus:                       16.600   Durbin-Watson:                   1.940\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.765\n",
      "Skew:                           0.689   Prob(JB):                      0.00169\n",
      "Kurtosis:                       2.192   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM interventions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "                df      sum_sq   mean_sq       F    PR(>F)\n",
      "Explanation    1.0    5.208333  5.208333  1.2514  0.265557\n",
      "Residual     118.0  491.116667  4.162006     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "\n",
    "llm_DF['condition'] = pd.Categorical(llm_DF['condition'], categories=['Hashtags','Explanation' ], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "llm_data_dummies = pd.get_dummies(llm_DF['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "llm_data_with_dummies = pd.concat([llm_DF, llm_data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (llm1, llm2, llm3) as predictors\n",
    "model = ols('fsa_score ~ Explanation', data=llm_data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.010\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1.251\n",
      "Date:                Mon, 16 Dec 2024   Prob (F-statistic):              0.266\n",
      "Time:                        16:55:15   Log-Likelihood:                -254.82\n",
      "No. Observations:                 120   AIC:                             513.6\n",
      "Df Residuals:                     118   BIC:                             519.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               6.5333      0.263     24.806      0.000       6.012       7.055\n",
      "Explanation[T.True]    -0.4167      0.372     -1.119      0.266      -1.154       0.321\n",
      "==============================================================================\n",
      "Omnibus:                       16.078   Durbin-Watson:                   2.077\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.417\n",
      "Skew:                           0.974   Prob(JB):                     6.08e-05\n",
      "Kurtosis:                       2.703   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to csv llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

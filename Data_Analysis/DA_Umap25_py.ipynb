{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "- Data Analysis for: Nudging Healthy Choices: Leveraging LLM-Generated Hashtags and Explanations in Personalized Food Recommendations\n",
    "- UMAP2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload \n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./rd_data')\n",
    "from rd_data import *\n",
    "\n",
    "palette = 'Set2'\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract approved\n",
    "def approved(prolific_export_pth, personal_info_pth,profile_pth, selected_pth, evaluation_pth, condition_pth, n_condition):\n",
    "    DF = pd.read_csv(prolific_export_pth)\n",
    "    perInfo = pd.read_csv(personal_info_pth)\n",
    "    \n",
    "    profile = pd.read_csv(profile_pth)\n",
    "    profile = profile.drop(columns=['id','title'])\n",
    "    \n",
    "    selected = pd.read_csv(selected_pth)\n",
    "    selected = selected.drop(columns=['id','created','session_id'])\n",
    "    \n",
    "    evaluation = pd.read_csv(evaluation_pth)\n",
    "    evaluation = evaluation.drop(columns=['id','title','created','session_id'])\n",
    "    \n",
    "    \n",
    "    approved = DF.loc[DF.Status == 'APPROVED']\n",
    "    approved_Info = pd.merge(approved['Participant id'],perInfo, left_on='Participant id', right_on='session_id')\n",
    "    \n",
    "    approved_Info = approved_Info.drop(columns=['Participant id','title', 'created'])\n",
    "    approved_Info.rename(columns={'id':'person'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    Info_profile = pd.merge(approved_Info, profile, on='person')\n",
    "    Info_profile_selected = pd.merge(Info_profile, selected, on='person')\n",
    "    Info_profile_selected_eval = pd.merge(Info_profile_selected, evaluation, on='person')\n",
    "    \n",
    "    Info_profile_selected_eval.replace({'Strongly_Disagree':1, 'Disagree':2, 'Neutral':3, 'Agree':4, 'Strongly_Agree':5}, inplace=True)\n",
    "    Info_profile_selected_eval['condition'] = condition_pth\n",
    "    Info_profile_selected_eval['n_condition'] = n_condition\n",
    "    \n",
    "    return Info_profile_selected_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 49)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## no label approved \n",
    "prolific_export = './noLabel/No_ProlificExport.csv'\n",
    "personal_info = './noLabel/NoPersonalInfo.csv'\n",
    "profile = './noLabel/NoProfile.csv'\n",
    "selected = './noLabel/NoRecipe.csv'\n",
    "evaluation ='./noLabel/NoEvaluateChoices.csv'\n",
    "\n",
    "No_label_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'noLabel', 0)\n",
    "No_label_condition.person = No_label_condition.person + 1000\n",
    "No_label_condition.rename(\n",
    "    columns={\n",
    "        'understandability':'under_1',\n",
    "        'effectiveness':'under_2',\n",
    "        'nudge_eval':'under_3',\n",
    "    }, inplace=True    \n",
    ")\n",
    "\n",
    "No_label_condition[0:60].to_csv('./cnd_csv/Nolabel.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "## label condi\n",
    "prolific_export = './Labels/No_ProlificExport.csv'\n",
    "personal_info = './Labels/NoPersonalInfo.csv'\n",
    "profile = './Labels/NoProfile.csv'\n",
    "selected = './Labels/NoRecipe.csv'\n",
    "evaluation ='./Labels/NoEvaluateChoices.csv'\n",
    "\n",
    "Labels_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Label',1)\n",
    "Labels_condition.person = Labels_condition.person + 2000\n",
    "Labels_condition = Labels_condition[0:60]\n",
    "Labels_condition.rename(\n",
    "    columns={\n",
    "        'understandability':'under_1',\n",
    "        'satisfaction':'under_2',\n",
    "        'effectiveness':'under_3',\n",
    "        \n",
    "        'persuasiveness':'use_1',\n",
    "        'nudge_eval':'use_2'\n",
    "    }, inplace=True    \n",
    ")\n",
    "\n",
    "Labels_condition.to_csv('./cnd_csv/labels.csv', index=False)\n",
    "\n",
    "## hash\n",
    "prolific_export = './Hashtags/No_ProlificExport.csv'\n",
    "personal_info = './Hashtags/NoPersonalInfo.csv'\n",
    "profile = './Hashtags/NoProfile.csv'\n",
    "selected = './Hashtags/NoRecipe.csv'\n",
    "evaluation ='./Hashtags/NoEvaluateChoices.csv'\n",
    "\n",
    "Hashtags_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Hashtags',3)\n",
    "Hashtags_condition.person = Hashtags_condition.person + 3000\n",
    "Hashtags_condition = Hashtags_condition[0:60]\n",
    "Hashtags_condition.rename(\n",
    "    columns={\n",
    "        'understandability':'under_1',\n",
    "        'satisfaction':'under_2',\n",
    "        'effectiveness':'under_3',\n",
    "        \n",
    "        'persuasiveness':'use_1',\n",
    "        'nudge_eval':'use_2'\n",
    "    }, inplace=True    \n",
    ")\n",
    "Hashtags_condition.to_csv('./cnd_csv/hashtags.csv', index=False)\n",
    "\n",
    "## Explanation\n",
    "prolific_export = './Explanation/No_ProlificExport.csv'\n",
    "personal_info = './Explanation/NoPersonalInfo.csv'\n",
    "profile = './Explanation/NoProfile.csv'\n",
    "selected = './Explanation/NoRecipe.csv'\n",
    "evaluation ='./Explanation/NoEvaluateChoices.csv'\n",
    "\n",
    "Explanation_condition = approved(prolific_export, personal_info,profile, selected, evaluation, 'Explanation',4)\n",
    "Explanation_condition.person = Explanation_condition.person + 5000\n",
    "Explanation_condition =  Explanation_condition[0:60]\n",
    "Explanation_condition.rename(\n",
    "    columns={\n",
    "        'understandability':'under_1',\n",
    "        'satisfaction':'under_2',\n",
    "        'effectiveness':'under_3',\n",
    "        \n",
    "        'persuasiveness':'use_1',\n",
    "        'nudge_eval':'use_2'\n",
    "    }, inplace=True    \n",
    ")\n",
    "Explanation_condition.to_csv('./cnd_csv/explanation.csv', index=False)\n",
    "\n",
    "\n",
    "allCondition = pd.concat([No_label_condition, Labels_condition, Hashtags_condition, Explanation_condition], axis=0)\n",
    "allCondition.to_csv('./cnd_csv/allCondition.csv', index=False)\n",
    "allCondition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "noLabel        60\n",
       "Label          60\n",
       "Hashtags       60\n",
       "Explanation    60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "b25_35      83\n",
       "b35_45      60\n",
       "b45_55      41\n",
       "b18_24      31\n",
       "bover_55    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Female            145\n",
       "Male               93\n",
       "refuse_to_disc      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "BA                  100\n",
       "High_school          81\n",
       "MSc                  50\n",
       "Doctorate             4\n",
       "Not                   3\n",
       "Less_high_school      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     condition healthiness  count  percentage\n",
      "0  Explanation     healthy     50   83.333333\n",
      "1  Explanation   unhealthy     10   16.666667\n",
      "2     Hashtags     healthy     45   75.000000\n",
      "3     Hashtags   unhealthy     15   25.000000\n",
      "4        Label     healthy     51   85.000000\n",
      "5        Label   unhealthy      9   15.000000\n",
      "6      noLabel     healthy     37   61.666667\n",
      "7      noLabel   unhealthy     23   38.333333\n"
     ]
    }
   ],
   "source": [
    "# Group by 'condition' and 'Healthiness'\n",
    "grouped = allCondition.groupby(['condition', 'healthiness']).size().reset_index(name='count')\n",
    "# Calculate total counts per condition\n",
    "total_per_condition = grouped.groupby('condition')['count'].transform('sum')\n",
    "\n",
    "# Add a new column for percentage\n",
    "grouped['percentage'] = (grouped['count'] / total_per_condition) * 100\n",
    "# Display the result\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fsa_score\n",
       "6     101\n",
       "10     55\n",
       "5      52\n",
       "4      30\n",
       "11      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.fsa_score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA across all conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 df      sum_sq    mean_sq         F    PR(>F)\n",
      "C(condition)    3.0   58.750000  19.583333  4.690936  0.003346\n",
      "Residual      236.0  985.233333   4.174718       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Fit the OLS model for 'Labelling Condition' only (no interactions with other factors)\n",
    "model = ols('fsa_score ~ C(condition)', data=allCondition).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "                df      sum_sq    mean_sq         F    PR(>F)\n",
      "Label          1.0   16.805556  16.805556  4.025555  0.045957\n",
      "Explanation    1.0   25.069444  25.069444  6.005064  0.014992\n",
      "Hashtags       1.0   16.875000  16.875000  4.042190  0.045514\n",
      "Residual     236.0  985.233333   4.174718       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "df_condition = allCondition\n",
    "df_condition['condition'] = pd.Categorical(df_condition['condition'], categories=['noLabel', 'Label','Explanation', 'Hashtags'], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "data_dummies = pd.get_dummies(df_condition['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "data_with_dummies = pd.concat([df_condition, data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (label1, label2, label3) as predictors\n",
    "model = ols('fsa_score ~ Label + Explanation+Hashtags', data=data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F-statistics: These show how much each condition (relative to \"nolabel\") affects the variance in the FSA_score.\n",
    "\n",
    "        - The F-statistic for explanation is 6.00, which indicates the amount of variance explained by this condition compared to nolabel.\n",
    "        - The F-statistic for hashtags is  4.042190, and labels is 4.025555, both of which show the amount of variance explained by these conditions compared to nolabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.056\n",
      "Model:                            OLS   Adj. R-squared:                  0.044\n",
      "Method:                 Least Squares   F-statistic:                     4.691\n",
      "Date:                Mon, 27 Jan 2025   Prob (F-statistic):            0.00335\n",
      "Time:                        15:40:50   Log-Likelihood:                -510.01\n",
      "No. Observations:                 240   AIC:                             1028.\n",
      "Df Residuals:                     236   BIC:                             1042.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               7.2833      0.264     27.612      0.000       6.764       7.803\n",
      "Label[T.True]          -1.2500      0.373     -3.351      0.001      -1.985      -0.515\n",
      "Explanation[T.True]    -1.1667      0.373     -3.127      0.002      -1.902      -0.432\n",
      "Hashtags[T.True]       -0.7500      0.373     -2.011      0.046      -1.485      -0.015\n",
      "==============================================================================\n",
      "Omnibus:                       28.067   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.692\n",
      "Skew:                           0.831   Prob(JB):                     2.16e-07\n",
      "Kurtosis:                       2.446   Cond. No.                         4.79\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  LLM and Labels intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_DF = allCondition.loc[(allCondition['condition'] == 'noLabel') | (allCondition['condition'] == 'Label')]\n",
    "llm_DF = allCondition.loc[(allCondition['condition'] == 'Hashtags') | (allCondition['condition'] == 'Explanation')]\n",
    "\n",
    "label_DF.to_csv('./cnd_csv/labels_data.csv', index=False)\n",
    "llm_DF.to_csv('./cnd_csv/llm_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "Explanation    60\n",
       "Hashtags       60\n",
       "noLabel         0\n",
       "Label           0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_DF.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "             df      sum_sq    mean_sq          F    PR(>F)\n",
      "Label       1.0   46.875000  46.875000  11.194219  0.001101\n",
      "Residual  118.0  494.116667   4.187429        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "\n",
    "label_DF['condition'] = pd.Categorical(label_DF['condition'], categories=['noLabel', 'Label'], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "label_data_dummies = pd.get_dummies(label_DF['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "label_data_with_dummies = pd.concat([label_DF, label_data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (label1, label2, label3) as predictors\n",
    "model = ols('fsa_score ~ Label', data=label_data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.079\n",
      "Method:                 Least Squares   F-statistic:                     11.19\n",
      "Date:                Mon, 27 Jan 2025   Prob (F-statistic):            0.00110\n",
      "Time:                        15:40:50   Log-Likelihood:                -255.19\n",
      "No. Observations:                 120   AIC:                             514.4\n",
      "Df Residuals:                     118   BIC:                             520.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         7.2833      0.264     27.570      0.000       6.760       7.806\n",
      "Label[T.True]    -1.2500      0.374     -3.346      0.001      -1.990      -0.510\n",
      "==============================================================================\n",
      "Omnibus:                       16.600   Durbin-Watson:                   1.940\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.765\n",
      "Skew:                           0.689   Prob(JB):                      0.00169\n",
      "Kurtosis:                       2.192   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM interventions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "                df      sum_sq   mean_sq       F    PR(>F)\n",
      "Explanation    1.0    5.208333  5.208333  1.2514  0.265557\n",
      "Residual     118.0  491.116667  4.162006     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "\n",
    "llm_DF['condition'] = pd.Categorical(llm_DF['condition'], categories=['Hashtags','Explanation' ], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "llm_data_dummies = pd.get_dummies(llm_DF['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "llm_data_with_dummies = pd.concat([llm_DF, llm_data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (llm1, llm2, llm3) as predictors\n",
    "model = ols('fsa_score ~ Explanation', data=llm_data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              fsa_score   R-squared:                       0.010\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1.251\n",
      "Date:                Mon, 27 Jan 2025   Prob (F-statistic):              0.266\n",
      "Time:                        15:40:50   Log-Likelihood:                -254.82\n",
      "No. Observations:                 120   AIC:                             513.6\n",
      "Df Residuals:                     118   BIC:                             519.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               6.5333      0.263     24.806      0.000       6.012       7.055\n",
      "Explanation[T.True]    -0.4167      0.372     -1.119      0.266      -1.154       0.321\n",
      "==============================================================================\n",
      "Omnibus:                       16.078   Durbin-Watson:                   2.077\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.417\n",
      "Skew:                           0.974   Prob(JB):                     6.08e-05\n",
      "Kurtosis:                       2.703   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "noLabel        60\n",
       "Label          60\n",
       "Explanation    60\n",
       "Hashtags       60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for CFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "noLabel        60\n",
       "Label          60\n",
       "Explanation    60\n",
       "Hashtags       60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Transform the negatively formulate questions\n",
    "allCondition[['FK_12']] = 6 -  allCondition[['FK_12']]\n",
    "allCondition[['sus_4']] = 6 -  allCondition[['sus_4']]\n",
    "allCondition.know_many = 6 - allCondition.know_many\n",
    "allCondition.easy_choice = 6 - allCondition.easy_choice\n",
    "allCondition.unders_sys = 6 - allCondition.unders_sys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User evaluation mean\n",
    "allCondition['choice_satisfaction'] = allCondition[['liked_recipes','prepare_recipes','fit_preference','recommend_recipe']].mean(axis=1)\n",
    "allCondition['choice_difficulty'] = allCondition[['many_to_choose','easy_choice','choice_overwhelming']].mean(axis=1)\n",
    "allCondition['perceived_effort'] = allCondition[['sys_time','unders_sys','many_actions']].mean(axis=1)\n",
    "allCondition['SFD'] = allCondition[['FK_9','FK_10','FK_11','FK_12']].mean(axis=1)\n",
    "allCondition['Sustain'] = allCondition[['sus_1', 'sus_2', 'sus_3', 'sus_4']].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCondition['understand'] = allCondition[['under_1','under_2','under_3']].mean(axis=1)\n",
    "allCondition['usability'] = allCondition[['use_1','use_2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCondition.to_csv('./cnd_csv/cfa_DF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usability test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nudging conditions\n",
    "nudge_df = allCondition.loc[allCondition.condition != 'noLabel']\n",
    "nudge_df.to_csv('./cnd_csv/nudge_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudge_df = pd.read_csv('./cnd_csv/nudge_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "Label          60\n",
       "Hashtags       60\n",
       "Explanation    60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nudge_df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for the model with dummy variables:\n",
      "                df      sum_sq    mean_sq          F        PR(>F)\n",
      "Explanation    1.0    1.002778   1.002778   1.132594  2.886724e-01\n",
      "Hashtags       1.0   24.300000  24.300000  27.445800  4.554111e-07\n",
      "Residual     177.0  156.712500   0.885381        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# Recode the 'Condition' column to set 'nolabel' as the baseline\n",
    "# The 'nolabel' category will be the reference category (baseline)\n",
    "df_condition = nudge_df\n",
    "df_condition['condition'] = pd.Categorical(df_condition['condition'], categories=['Label','Explanation', 'Hashtags'], ordered=False)\n",
    "# Create dummy variables for 'Condition', excluding 'nolabel' to be the reference category\n",
    "data_dummies = pd.get_dummies(df_condition['condition'], drop_first=True)\n",
    "\n",
    "# Add the dummy variables to the original data\n",
    "data_with_dummies = pd.concat([df_condition, data_dummies], axis=1)\n",
    "\n",
    "# Fit the OLS model using the dummy variables (label1, label2, label3) as predictors\n",
    "model = ols('usability ~Explanation+Hashtags', data=data_with_dummies).fit()\n",
    "\n",
    "# Perform the ANOVA to check the significance of the model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA results for the model with dummy variables:\")\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              usability   R-squared:                       0.139\n",
      "Model:                            OLS   Adj. R-squared:                  0.129\n",
      "Method:                 Least Squares   F-statistic:                     14.29\n",
      "Date:                Mon, 27 Jan 2025   Prob (F-statistic):           1.77e-06\n",
      "Time:                        15:40:51   Log-Likelihood:                -242.94\n",
      "No. Observations:                 180   AIC:                             491.9\n",
      "Df Residuals:                     177   BIC:                             501.5\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               2.7646      0.053     52.558      0.000       2.661       2.868\n",
      "Label[T.True]           1.3187      0.101     13.093      0.000       1.120       1.518\n",
      "Explanation[T.True]     1.0271      0.101     10.197      0.000       0.828       1.226\n",
      "Hashtags[T.True]        0.4187      0.101      4.157      0.000       0.220       0.618\n",
      "==============================================================================\n",
      "Omnibus:                        3.732   Durbin-Watson:                   1.728\n",
      "Prob(Omnibus):                  0.155   Jarque-Bera (JB):                3.571\n",
      "Skew:                          -0.288   Prob(JB):                        0.168\n",
      "Kurtosis:                       2.621   Cond. No.                     7.07e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.8e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Model summary to check the overall F-statistic\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcondition_no_use = allCondition.drop(columns=['use_1','use_2','usability'])\n",
    "allcondition_no_use.to_csv('./cnd_csv/allcondition_no_use.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    usability\n",
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "..        ...\n",
       "55        4.0\n",
       "56        4.5\n",
       "57        4.0\n",
       "58        2.5\n",
       "59        4.0\n",
       "\n",
       "[240 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCondition[['usability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = allCondition.understand.mean()\n",
    "allCondition['under_level'] = 'High'\n",
    "allCondition.loc[allCondition.understand <= mean, 'under_level' ] = 'Low'\n",
    "\n",
    "mean = allCondition.SFD.mean()\n",
    "allCondition['SFD_level'] = 'High'\n",
    "allCondition.loc[allCondition.understand <= mean, 'SFD_level' ] = 'Low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCondition.to_csv('cnd_csv/allCond.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
